{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,  precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.attacks import FastGradientMethod, ProjectedGradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train_val), (x_test, y_test_val) = mnist.load_data()\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test_cnn = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ann = x_train.reshape(x_train.shape[0], img_rows* img_cols)\n",
    "x_test_ann = x_test.reshape(x_test.shape[0], img_rows* img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnn = to_categorical(y_train_val)\n",
    "y_test_cnn = to_categorical(y_test_val)\n",
    "y_train_ann = to_categorical(y_train_val)\n",
    "y_test_ann = to_categorical(y_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "adadelta = Adadelta()\n",
    "loss = categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_1(activation):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation=activation, input_shape=input_shape)) \n",
    "    \n",
    "    model.add(Conv2D(16, (3, 3), activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=adadelta, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_cnn_1 = cnn_model_1(activation)\n",
    "model_cnn_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_cnn_1 = model_cnn_1.fit(x_train_cnn, y_train_cnn, validation_data=(x_test_cnn,y_test_cnn), \n",
    "                                   epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_cnn1 = model_cnn_1.predict_classes(x_test_cnn)\n",
    "print(classification_report(y_test_val, pred_val_cnn1))\n",
    "acc_cnn = accuracy_score(y_test_val, pred_val_cnn1)\n",
    "prec_cnn = precision_score(y_test_val, pred_val_cnn1, average = 'weighted')\n",
    "rec_cnn = recall_score(y_test_val, pred_val_cnn1, average = 'weighted')\n",
    "f1_cnn = f1_score(y_test_val, pred_val_cnn1, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model_1():\n",
    "    \n",
    "    model = Sequential()  \n",
    "    \n",
    "    model.add(Dense(100, activation='relu', input_dim=784))\n",
    "    model.add(Dense(200, activation='relu')) \n",
    "    model.add(Dense(200, activation='relu')) \n",
    "    model.add(Dense(200, activation='relu')) \n",
    "    model.add(Dense(100, activation='relu')) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "         \n",
    "    model.compile(loss=loss, optimizer=adadelta, metrics=['accuracy'])\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 200,210\n",
      "Trainable params: 200,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense_1 = dense_model_1()\n",
    "model_dense_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 2.4694 - acc: 0.7761 - val_loss: 0.3590 - val_acc: 0.9038\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.2129 - acc: 0.9404 - val_loss: 0.1857 - val_acc: 0.9508\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1418 - acc: 0.9589 - val_loss: 0.1721 - val_acc: 0.9519\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.1131 - acc: 0.9676 - val_loss: 0.1521 - val_acc: 0.9568\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0895 - acc: 0.9742 - val_loss: 0.1333 - val_acc: 0.9684\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0758 - acc: 0.9783 - val_loss: 0.1358 - val_acc: 0.9689\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0652 - acc: 0.9809 - val_loss: 0.1401 - val_acc: 0.9689\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0560 - acc: 0.9842 - val_loss: 0.1485 - val_acc: 0.9707\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0483 - acc: 0.9858 - val_loss: 0.1448 - val_acc: 0.9697\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0435 - acc: 0.9876 - val_loss: 0.1817 - val_acc: 0.9681\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0414 - acc: 0.9886 - val_loss: 0.1460 - val_acc: 0.9739\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0390 - acc: 0.9899 - val_loss: 0.1622 - val_acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "history_dense_1 = model_dense_1.fit(x_train_ann, y_train_ann, validation_data=(x_test_ann,y_test_ann), \n",
    "                                   epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.94      0.98      0.96      1032\n",
      "           3       0.97      0.96      0.96      1010\n",
      "           4       0.98      0.96      0.97       982\n",
      "           5       0.99      0.95      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.96      0.97      0.97       974\n",
      "           9       0.97      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val_dense_1 = model_dense_1.predict_classes(x_test_ann)\n",
    "print(classification_report(y_test_val, pred_val_dense_1))\n",
    "acc_ann = accuracy_score(y_test_val, pred_val_dense_1)\n",
    "prec_ann = accuracy_score(y_test_val, pred_val_dense_1)\n",
    "rec_ann = recall_score(y_test_val, pred_val_dense_1, average = 'weighted')\n",
    "f1_ann = f1_score(y_test_val, pred_val_dense_1, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benign Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['accuracy', 'precision', 'recall', 'f1-score']\n",
    "x = np.arange(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar(x - width/2, [acc_ann, prec_ann, rec_ann, f1_ann], width, label='ANN')\n",
    "ax.bar(x + width/2, [acc_cnn, prec_cnn, rec_cnn, f1_cnn], width, label='CNN')\n",
    "\n",
    "ax.set_title('Scores by method')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ann = KerasClassifier(model=model_dense_1, use_logits=False)\n",
    "attack_ann_1 = ProjectedGradientDescent(classifier_ann, eps=0.3, eps_step=0.01, max_iter=40, targeted=False, \n",
    "                                  num_random_init=True)\n",
    "adv_fg_ann = attack_ann_1.generate(x=x_test_ann[0:1], y=y_test_val[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22525461, -0.02212151,  0.28771108, -0.11035471,  0.26407635,\n",
       "        -0.28647617, -0.10324833, -0.12606467,  0.19889037, -0.21452819,\n",
       "        -0.2684212 ,  0.28820813, -0.00412485,  0.26711786, -0.06291749,\n",
       "        -0.21975133, -0.18388362,  0.28052625, -0.1906204 , -0.16976005,\n",
       "         0.00985838, -0.23260275,  0.00725091,  0.09932746,  0.01029759,\n",
       "         0.15453286,  0.16805409, -0.01343874,  0.26909167,  0.22540615,\n",
       "         0.10137677, -0.15257187, -0.13587081,  0.22813544,  0.16192068,\n",
       "        -0.01411887,  0.09819537, -0.12048398,  0.268644  , -0.24098355,\n",
       "        -0.05551402, -0.10550387,  0.26596698,  0.10927453,  0.23154986,\n",
       "        -0.2558589 , -0.29671988,  0.25350595, -0.05438451,  0.27488053,\n",
       "         0.24116418,  0.04729297, -0.16360563,  0.15920125,  0.1474858 ,\n",
       "         0.2805056 , -0.05409695,  0.06749721,  0.2760368 , -0.2640701 ,\n",
       "        -0.08975748, -0.23067617,  0.08322582,  0.23411784, -0.01579057,\n",
       "         0.05679958,  0.10842209,  0.05450231,  0.22970086,  0.03660034,\n",
       "         0.27522704,  0.16355321,  0.21284224, -0.09064038, -0.07343376,\n",
       "        -0.16886003, -0.11542407, -0.08969319, -0.09208118, -0.26509216,\n",
       "        -0.07155314, -0.24654438, -0.07513163, -0.09214956, -0.07480144,\n",
       "        -0.24177158,  0.05466225, -0.09778485, -0.28327245, -0.2838922 ,\n",
       "         0.29305717,  0.1758524 , -0.24499802,  0.19382842,  0.05450201,\n",
       "         0.24994698, -0.23792034, -0.02401186,  0.19299278,  0.04031673,\n",
       "         0.26662478,  0.11282181, -0.11017162, -0.12158331, -0.2537932 ,\n",
       "         0.15179452, -0.06110724,  0.0844036 ,  0.08918306,  0.07959604,\n",
       "         0.07372583,  0.05564294, -0.00571351, -0.2239377 , -0.16158581,\n",
       "         0.23617579,  0.19075504, -0.05243109, -0.16526614, -0.26924464,\n",
       "        -0.18780363,  0.16041917, -0.14946862,  0.18256792, -0.06504402,\n",
       "         0.26412806, -0.17217255,  0.04813865,  0.29760832, -0.02544681,\n",
       "         0.08023035,  0.161888  ,  0.25951415, -0.2786495 , -0.05945132,\n",
       "        -0.20177099, -0.2745299 ,  0.27716726, -0.14697628, -0.00032089,\n",
       "        -0.1423641 , -0.06250651, -0.01070572,  0.15448926,  0.227585  ,\n",
       "        -0.2596081 , -0.18724303,  0.27778062, -0.04111057, -0.26051465,\n",
       "        -0.21397765, -0.20739634, -0.27885643, -0.13569234, -0.05657788,\n",
       "        -0.15022005, -0.08091445,  0.2746744 ,  0.20586832, -0.03609981,\n",
       "        -0.2562254 , -0.01807957, -0.21959741,  0.26437032,  0.17834753,\n",
       "         0.15242444,  0.10594492,  0.03692823, -0.12034368,  0.02188927,\n",
       "         0.21908022, -0.20975056,  0.11930639,  0.24314319,  0.02847775,\n",
       "        -0.07412971, -0.16112141,  0.21070573,  0.12502295,  0.20727296,\n",
       "        -0.2982201 ,  0.22821623,  0.12840125,  0.1869931 ,  0.13317299,\n",
       "        -0.00469523, -0.01422943, -0.2005435 , -0.15510468, -0.16406046,\n",
       "        -0.15297687,  0.1581399 ,  0.14860603, -0.13127285,  0.11568481,\n",
       "         0.12099312,  0.23510802, -0.21275544,  0.18904494,  0.1207751 ,\n",
       "         0.14835858,  0.29731196,  0.1621933 , -0.05197144, -0.24415588,\n",
       "        -0.20289612,  0.0104332 , -0.2518425 ,  0.00664861,  0.20652121,\n",
       "         0.2637236 ,  0.1287078 , -0.17280734, -0.14876522, -0.21983404,\n",
       "         0.16565576, -0.16961034,  0.11390936, -0.15824671, -0.01248194,\n",
       "         0.16488057, -0.07300913, -0.2956094 , -0.1635075 , -0.06243996,\n",
       "         0.1884559 , -0.04787488, -0.22713293,  0.02583102, -0.20984372,\n",
       "        -0.1499939 , -0.1806488 , -0.26402283,  0.22639465, -0.22035217,\n",
       "        -0.11076355,  0.1446991 , -0.02087402,  0.07170105, -0.00161743,\n",
       "         0.26715088, -0.26591492, -0.1362915 , -0.20986938,  0.19877625,\n",
       "         0.2951889 ,  0.09852628,  0.04681339,  0.10369236, -0.27487442,\n",
       "        -0.04013632, -0.27076825,  0.10076578, -0.13473387, -0.1113634 ,\n",
       "         0.22231129, -0.20355944, -0.08615028,  0.13439941,  0.17010498,\n",
       "         0.00683594, -0.12002563,  0.04907227, -0.06608582,  0.18954468,\n",
       "         0.29005432, -0.03132629,  0.24996948, -0.03570557,  0.1421051 ,\n",
       "         0.0249176 ,  0.13873291, -0.23078918, -0.03918457, -0.0921443 ,\n",
       "        -0.29001886,  0.16863778, -0.21470778,  0.18800382, -0.22200751,\n",
       "        -0.04516775, -0.18959469,  0.12177982, -0.0255256 ,  0.04417891,\n",
       "         0.06899722, -0.21861866,  0.04515213,  0.21996354,  0.2146498 ,\n",
       "         0.06443073, -0.2700653 , -0.0769043 ,  0.13061428,  0.11727905,\n",
       "         0.28980255, -0.20632172,  0.2161293 , -0.1296997 , -0.13645935,\n",
       "        -0.09164429,  0.10657501,  0.21298675, -0.1750362 , -0.08405897,\n",
       "        -0.18472743, -0.07457417,  0.22150734, -0.12994011, -0.24668722,\n",
       "         0.06600071,  0.27132508, -0.05840163, -0.06943959,  0.04293647,\n",
       "         0.10785427, -0.19179715,  0.04153971, -0.2714528 , -0.12492023,\n",
       "         0.21111917, -0.05096281, -0.18113981, -0.09664232, -0.22304405,\n",
       "         0.18750592, -0.08559418,  0.08979797, -0.00392151, -0.00694466,\n",
       "        -0.11531258, -0.03130871, -0.16420601, -0.03604521, -0.23422281,\n",
       "         0.23751941,  0.07711104,  0.1752814 , -0.16359468,  0.11162362,\n",
       "         0.2130974 ,  0.09466855, -0.2132148 , -0.05373063, -0.02511054,\n",
       "         0.20321466,  0.26658514,  0.18603481, -0.09960964, -0.21552871,\n",
       "        -0.01297615, -0.17528549,  0.08250406,  0.03639793,  0.08152771,\n",
       "        -0.18989563, -0.26971436,  0.28274027,  0.04308685,  0.1669916 ,\n",
       "         0.2544924 ,  0.20578372, -0.2877492 , -0.11222826,  0.27828267,\n",
       "        -0.29355147, -0.20118995,  0.07374946,  0.21062943, -0.14789055,\n",
       "        -0.23321132,  0.07692902, -0.15217404, -0.09073944, -0.00463708,\n",
       "        -0.17393932,  0.03197701,  0.13849819,  0.19433492,  0.07148101,\n",
       "        -0.2597543 ,  0.01593018,  0.0944519 , -0.20123291, -0.00775528,\n",
       "         0.28097492, -0.05040503,  0.23236401,  0.07905623,  0.13430661,\n",
       "         0.29488924,  0.17632838, -0.12393087, -0.1080439 , -0.27258602,\n",
       "         0.21341847,  0.29559827,  0.09223814,  0.19655137,  0.27774084,\n",
       "        -0.25968507,  0.14593026, -0.1528428 ,  0.22478843,  0.14066757,\n",
       "        -0.2571186 ,  0.1938768 ,  0.05576366,  0.25367355, -0.2266388 ,\n",
       "        -0.25790405, -0.27027893, -0.12541772, -0.04363653,  0.07961047,\n",
       "        -0.02194969, -0.14409663,  0.03147206, -0.2872521 , -0.14612591,\n",
       "        -0.2410232 , -0.27359563, -0.18341741, -0.23684897, -0.11629709,\n",
       "         0.02721218, -0.29016733, -0.24247336, -0.26184103,  0.13698407,\n",
       "        -0.08055635, -0.2860138 , -0.2951309 , -0.14901933,  0.07091169,\n",
       "        -0.12569456,  0.06393433,  0.06150818,  0.020401  ,  0.1266017 ,\n",
       "        -0.26782322,  0.22937414,  0.22017698,  0.21024169, -0.11169448,\n",
       "        -0.2964896 , -0.01338591,  0.08724976, -0.04314199,  0.20224807,\n",
       "        -0.26194957, -0.1885962 ,  0.18507266, -0.10977782,  0.11785424,\n",
       "        -0.15871212, -0.23560533,  0.2291638 , -0.16588981,  0.12366863,\n",
       "         0.29298973, -0.05569746, -0.20578459,  0.11719418,  0.09361267,\n",
       "         0.0144043 , -0.2796135 , -0.12455548, -0.20693009,  0.21955916,\n",
       "         0.14517105, -0.12927948,  0.23194672,  0.18316755, -0.21664493,\n",
       "         0.07617214, -0.11280214,  0.07071407,  0.16948195, -0.18482786,\n",
       "        -0.28545198,  0.02719455, -0.02828871,  0.29578078, -0.22330122,\n",
       "        -0.04114992,  0.25027022,  0.044527  ,  0.24801289,  0.2633532 ,\n",
       "         0.25664237, -0.20855713,  0.29122925,  0.27194214,  0.03755184,\n",
       "        -0.04118752,  0.03266334,  0.01338632, -0.03244865, -0.17208986,\n",
       "         0.13660254,  0.0403204 , -0.03592947,  0.04856186, -0.19865008,\n",
       "        -0.20775163,  0.03584358,  0.22262633,  0.24974994, -0.10701296,\n",
       "        -0.0843103 ,  0.08778528,  0.26322556, -0.29973876,  0.09106117,\n",
       "        -0.02299625, -0.03763599, -0.2094681 ,  0.20639801, -0.22740173,\n",
       "         0.10766602,  0.14539719, -0.02636033, -0.03425065, -0.09158493,\n",
       "        -0.03944824,  0.02762141,  0.27621344,  0.21003005, -0.09053479,\n",
       "         0.05114572,  0.20868061,  0.02056414,  0.20807643,  0.10843363,\n",
       "         0.21116214,  0.20062043, -0.07879983, -0.15071918, -0.2659186 ,\n",
       "         0.18001556, -0.04127684,  0.14108437, -0.21002549,  0.21761325,\n",
       "        -0.21572685,  0.08863831,  0.22647095, -0.08352661, -0.12975265,\n",
       "        -0.12722613,  0.26169744, -0.2307583 , -0.08376815,  0.2867102 ,\n",
       "         0.23054193, -0.07898297, -0.00292978,  0.26251322, -0.08513036,\n",
       "        -0.02690019, -0.21462587,  0.08825204,  0.16000102, -0.11757878,\n",
       "         0.20598319, -0.2946832 ,  0.2007079 ,  0.13991387, -0.2151277 ,\n",
       "         0.06454621,  0.21926819,  0.24814415,  0.2500763 , -0.13909912,\n",
       "        -0.2386322 ,  0.18364334, -0.0459895 , -0.03139299,  0.19099595,\n",
       "         0.09456158, -0.26191407, -0.0602202 ,  0.24195172,  0.2308539 ,\n",
       "         0.22730199, -0.24278764,  0.29933706, -0.25196442,  0.10901179,\n",
       "        -0.29427442,  0.04664567,  0.06320103, -0.24345635,  0.28858125,\n",
       "         0.03789212, -0.16188909, -0.20283763, -0.01884385,  0.16771902,\n",
       "         0.03986359,  0.18569946, -0.03903198, -0.2340622 ,  0.26374224,\n",
       "         0.04937721, -0.1345231 ,  0.04888727, -0.13429432,  0.20365767,\n",
       "         0.26009077, -0.22696236,  0.12386005,  0.01918937, -0.18845099,\n",
       "        -0.0739018 , -0.19834922,  0.18361752,  0.0363914 ,  0.04333236,\n",
       "         0.07017612, -0.18337177, -0.24361776,  0.27363724,  0.05144825,\n",
       "        -0.03895717,  0.20862877, -0.25314713, -0.08067322, -0.27990723,\n",
       "         0.254776  , -0.10481036,  0.2748817 , -0.19170578,  0.16062123,\n",
       "         0.0399542 , -0.16249315,  0.25730693, -0.21916202,  0.09782682,\n",
       "         0.27880424, -0.00700298,  0.2364555 , -0.02553108, -0.287904  ,\n",
       "         0.10043355,  0.28098816, -0.13525748, -0.19521385, -0.29900244,\n",
       "         0.20572466,  0.05870339, -0.10211018,  0.15289739, -0.1732379 ,\n",
       "        -0.2130127 , -0.182724  , -0.0344696 ,  0.05784607, -0.04676009,\n",
       "         0.19389848, -0.22359793,  0.07961014,  0.27476916, -0.10939132,\n",
       "         0.056528  , -0.23410828,  0.2123642 ,  0.12612246,  0.02025861,\n",
       "         0.03126064, -0.24243708, -0.2012419 ,  0.20494351, -0.1626697 ,\n",
       "         0.08861952,  0.05445831,  0.12936252,  0.25640646,  0.29936266,\n",
       "         0.13136928, -0.28534564,  0.13462067, -0.15808105, -0.13334656,\n",
       "         0.27279663,  0.10599136,  0.20889549, -0.25665942, -0.24063458,\n",
       "        -0.2922159 ,  0.07664459,  0.18088035,  0.14755513, -0.09669264,\n",
       "        -0.02166261, -0.19054633,  0.26034153, -0.05609053,  0.16554834,\n",
       "        -0.25743252,  0.0829333 , -0.15868883,  0.24229583, -0.02687116,\n",
       "         0.26927614, -0.13395208,  0.15932812, -0.19210875, -0.1253791 ,\n",
       "         0.07614136, -0.24838257, -0.28256226, -0.10464478, -0.14493942,\n",
       "         0.02826962,  0.25663438, -0.07649957,  0.16122667,  0.11616061,\n",
       "         0.09541576,  0.01965754,  0.05965655,  0.05951784,  0.05896721,\n",
       "         0.2017514 ,  0.0968674 , -0.20541984,  0.21144286, -0.25602078,\n",
       "        -0.16285388, -0.16027305,  0.27788746, -0.20735818, -0.21274039,\n",
       "        -0.16482806, -0.2322971 ,  0.11630588, -0.2058258 , -0.25260925,\n",
       "         0.06137085,  0.074543  , -0.18212955, -0.06172095,  0.2617629 ,\n",
       "         0.03180378,  0.14623189,  0.06568593,  0.21328163, -0.05246418,\n",
       "        -0.22451684,  0.2307984 ,  0.14978549, -0.11921092,  0.2491871 ,\n",
       "         0.01625475,  0.29240504, -0.28168797, -0.01397863,  0.28377035,\n",
       "         0.13635463,  0.05539352,  0.25455332, -0.06114117,  0.18164161,\n",
       "        -0.2387726 ,  0.21463278, -0.08993449,  0.11439848, -0.09713849,\n",
       "        -0.09836753,  0.22398128, -0.29296544, -0.088934  ,  0.14525284,\n",
       "        -0.07006045,  0.2576886 ,  0.16358447, -0.25584003, -0.27285632,\n",
       "         0.12859713, -0.02265105, -0.04333068,  0.17857791]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_ann[0] - adv_fg_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sample :\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Original Sample :\")\n",
    "plt.imshow(x_test_ann[0].reshape((28,28)), cmap='Greys')\n",
    "plt.show()\n",
    "print(\"Adversarial Sample:\")\n",
    "plt.imshow(adv_fg_ann[0].reshape((28,28)), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        85\n",
      "           1       0.98      0.98      0.98       126\n",
      "           2       0.97      0.98      0.97       116\n",
      "           3       0.95      0.99      0.97       107\n",
      "           4       0.98      0.96      0.97       110\n",
      "           5       1.00      0.97      0.98        87\n",
      "           6       0.98      1.00      0.99        87\n",
      "           7       0.97      0.95      0.96        99\n",
      "           8       0.97      0.94      0.95        89\n",
      "           9       0.96      0.95      0.95        94\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_adv_fg_ann = attack_ann_1.generate(x=x_test_ann[0:1000], y=y_test_val[0:1000])\n",
    "pred_val_dense_2 = model_dense_1.predict_classes(x_adv_fg_ann)\n",
    "print(classification_report(y_test_val[0:1000], pred_val_dense_2))\n",
    "#acc_ann = accuracy_score(y_test_val, pred_val_dense_2)\n",
    "#prec_ann = accuracy_score(y_test_val, pred_val_dense_2)\n",
    "#rec_ann = recall_score(y_test_val, pred_val_dense_2, average = 'weighted')\n",
    "#f1_ann = f1_score(y_test_val, pred_val_dense_2, average = 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
